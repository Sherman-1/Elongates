{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "import re\n",
    "import yaml \n",
    "from utils.process import get_specie\n",
    "\n",
    "\n",
    "cov = 0.5\n",
    "\n",
    "# Load yaml file\n",
    "with open('/home/simon.herman/Bureau/Gits/Elongates/env.yaml', 'r') as f:\n",
    "    yaml_data = yaml.safe_load(f)\n",
    "    species_dict = {k: v for d in yaml_data['Regex'].values() for k, v in d.items()}\n",
    "    species_order = yaml_data['Species_order']['Scer']\n",
    "    re_dict = yaml_data['Regex']['Scer']\n",
    "\n",
    "\n",
    "def is_monophyletic(binary_vector):\n",
    "    \n",
    "    two_index = binary_vector.index(2)\n",
    "\n",
    "    ones_after_two = binary_vector[two_index:]\n",
    "    start_index = ones_after_two.index(1) + two_index\n",
    "    end_index = len(ones_after_two) - 1 - ones_after_two[::-1].index(1) + two_index\n",
    "\n",
    "    if 1 in binary_vector[:two_index] or 0 in binary_vector[start_index:end_index+1]:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "    \n",
    "def parse_blast_dataframe(row : tuple) -> tuple:\n",
    "\n",
    "    query_pattern = r'(.*?)-(cluster_n\\d+)'\n",
    "    subject_pattern = r'(.*?)-(cluster_n\\d+)-.*-(f\\d+)-.*'\n",
    "\n",
    "    query_id = row[0]\n",
    "    subject_id = row[1]\n",
    "    evalue = row[2]\n",
    "    qstart = row[3]\n",
    "    qend = row[4]\n",
    "    sstart = row[5]\n",
    "    send = row[6]\n",
    "    qseq = row[7]\n",
    "    sseq = row[8]\n",
    "    length = row[9]\n",
    "    blast_gapopen = row[10]\n",
    "    blast_gaps = row[11]\n",
    "\n",
    "\n",
    "\n",
    "    query_matches = re.match(query_pattern, query_id)\n",
    "    query_seq_id = query_matches.group(1) if query_matches else None\n",
    "    query_cluster = query_matches.group(2) if query_matches else None\n",
    "\n",
    "    subject_matches = re.match(subject_pattern, subject_id)\n",
    "    subject_seq_id = subject_matches.group(1) if subject_matches else None\n",
    "    subject_cluster = subject_matches.group(2) if subject_matches else None\n",
    "    subject_relative_frame = subject_matches.group(3) if subject_matches else None\n",
    "\n",
    "    is_same_cluster = int(query_cluster == subject_cluster)\n",
    "    q_specie = get_specie(re_dict, query_seq_id)\n",
    "    s_specie = get_specie(re_dict, subject_seq_id)\n",
    "\n",
    "    tuple_ = tuple([query_seq_id, subject_seq_id, evalue, qstart, qend, sstart, send, \n",
    "                    qseq, sseq, length, blast_gapopen, blast_gaps, query_cluster, subject_cluster, subject_relative_frame, \n",
    "                    is_same_cluster, q_specie, s_specie])\n",
    "    return tuple_\n",
    "\n",
    "\n",
    "def analyze_monophyly(dataframe, species_order):\n",
    "\n",
    "    tmp_id = list()\n",
    "    tmp_vector = list()\n",
    "    tmp_bool = list()\n",
    "\n",
    "    for query, matches in dataframe.groupby(\"qseqid\"):\n",
    "        if len(matches[\"q_specie\"].unique().to_list()) > 1:\n",
    "            raise KeyError(\"Multiple query species found\")\n",
    "        else:\n",
    "            q_specie = matches[\"q_specie\"].unique().to_list()[0]  # Supposedly only one query specie\n",
    "\n",
    "        species = matches[\"s_specie\"].unique().to_list()\n",
    "        species = [1 if item in species else 0 for item in species_order]\n",
    "        try:\n",
    "            index = species_order.index(q_specie)\n",
    "            species[index] = 2\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        tmp_id.append(query)\n",
    "        tmp_vector.append(str(species))\n",
    "        try:\n",
    "            tmp_bool.append(False if 0 in species[2 : len(species) - species[::-1].index(1)] else True)\n",
    "        except ValueError:\n",
    "            tmp_bool.append(True) # If only 2 in the vector, q_specie == s_specie \n",
    "\n",
    "\n",
    "    result_df = pl.DataFrame({\n",
    "        'query': tmp_id,\n",
    "        'vector': tmp_vector,\n",
    "        'is_monophyletic': tmp_bool\n",
    "    })\n",
    "\n",
    "    dataframe = dataframe.join(result_df, left_on=\"qseqid\", right_on=\"query\")\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def analyze_elongate_topology(dataframe):\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################\n",
    "\n",
    "# NTER\n",
    "\n",
    "####################\n",
    "\n",
    "columns =  [\"qseqid\", \"sseqid\", \"evalue\", \"qstart\", \"qend\", \"sstart\", \"send\", \"qseq\", \"sseq\", \"length\", \"blast_gapopen\", \"blast_gaps\"]\n",
    "df_blast_nter  = pl.read_csv(f\"output/{cov}/nter_five_{cov}.tsv\", separator=\"\\t\", has_header = False)\n",
    "df_blast_nter.columns = columns\n",
    "\n",
    "df_blast_nter = df_blast_nter.with_columns(\n",
    "    pl.lit(\"NA\").alias('query_cluster'),\n",
    "    pl.lit(\"NA\").alias('subject_cluster'),\n",
    "    pl.lit(\"NA\").alias('relative_frame'),\n",
    "    pl.lit(\"NA\").alias('same_cluster'),\n",
    "    pl.lit(\"NA\").alias('q_specie'),\n",
    "    pl.lit(\"NA\").alias('s_specie')\n",
    ")\n",
    "\n",
    "\n",
    "columns = df_blast_nter.columns\n",
    "df_blast_nter = df_blast_nter.apply(parse_blast_dataframe)\n",
    "df_blast_nter.columns = columns\n",
    "\n",
    "\n",
    "nter_elongates_data = pl.read_csv(f\"output/{cov}/{cov}_elongates.csv\", infer_schema_length = 5000).select(\"cluster_size\",\"seq_id\",\n",
    "                                                           \"Nter_gaps\",\"Nter_gap_openings\",\"Nter_nb_aa\",\n",
    "                                                           \"Nter_elongate_length\",\"Nter_ratio\",\n",
    "                                                           \"is_max_Nter\",\"is_min_Nter\",\n",
    "                                                           \"Nter_event_ID\",\"Nter_events\",\n",
    "                                                           \"Meth_after_Nter\")\n",
    "\n",
    "\n",
    "\n",
    "df_nter = df_blast_nter.join(nter_elongates_data, left_on=\"qseqid\", right_on=\"seq_id\", how = \"inner\")\n",
    "df_nter = df_nter.filter((pl.col(\"same_cluster\") == 1))\n",
    "df_nter = analyze_monophyly(df_nter, species_order)\n",
    "\n",
    "\n",
    "####################\n",
    "\n",
    "# CTER\n",
    "\n",
    "####################\n",
    "\n",
    "columns =  [\"qseqid\", \"sseqid\", \"evalue\", \"qstart\", \"qend\", \"sstart\", \"send\", \"qseq\", \"sseq\", \"length\", \"blast_gapopen\", \"blast_gaps\"]\n",
    "df_blast_cter  = pl.read_csv(f\"output/{cov}/cter_three_{cov}.tsv\", separator=\"\\t\", has_header = False)\n",
    "df_blast_cter.columns = columns\n",
    "\n",
    "\n",
    "\n",
    "df_blast_cter = df_blast_cter.with_columns(\n",
    "    pl.lit(\"NA\").alias('query_cluster'),\n",
    "    pl.lit(\"NA\").alias('subject_cluster'),\n",
    "    pl.lit(\"NA\").alias('relative_frame'),\n",
    "    pl.lit(\"NA\").alias('same_cluster'),\n",
    "    pl.lit(\"NA\").alias('q_specie'),\n",
    "    pl.lit(\"NA\").alias('s_specie')\n",
    ")\n",
    "\n",
    "\n",
    "columns = df_blast_cter.columns\n",
    "df_blast_cter = df_blast_cter.apply(parse_blast_dataframe)\n",
    "df_blast_cter.columns = columns\n",
    "\n",
    "\n",
    "cter_elongates_data = pl.read_csv(f\"output/{cov}/{cov}_elongates.csv\", infer_schema_length =5000).select(\"cluster_size\",\"seq_id\",\n",
    "                                                           \"Cter_gaps\",\"Cter_gap_openings\",\"Cter_nb_aa\",\n",
    "                                                           \"Cter_elongate_length\",\"Cter_ratio\",\n",
    "                                                           \"is_max_Cter\",\"is_min_Cter\",\n",
    "                                                           \"Cter_event_ID\",\"Cter_events\")\n",
    "\n",
    "\n",
    "\n",
    "df_cter = df_blast_cter.join(cter_elongates_data, left_on=\"qseqid\", right_on=\"seq_id\", how = \"inner\")\n",
    "df_cter = df_cter.filter((pl.col(\"same_cluster\") == 1))\n",
    "df_cter = analyze_monophyly(df_cter, species_order)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nter : (352, 31)\n",
      "Cter : (150, 30)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "common_sorting = (\n",
    "                ((pl.col(\"q_specie\") == \"Scer_NCBI\") | (pl.col(\"q_specie\") == \"Spar_NCBI\")) &\n",
    "                (pl.col(\"evalue\") < 0.5)  \n",
    "                 \n",
    "                     \n",
    "                )\n",
    "\n",
    "nter_filtered = df_nter.filter(common_sorting & (pl.col(\"Nter_elongate_length\") < 60))\n",
    "cter_filtered = df_cter.filter(common_sorting & (pl.col(\"Cter_elongate_length\") < 60))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Nter : {nter_filtered.shape}\")\n",
    "print(f\"Cter : {cter_filtered.shape}\")\n",
    "\n",
    "spe_nter = (pl.col(\"qstart\") < 5) & (pl.col(\"sstart\") < pl.col(\"length\") + 5) & (pl.col(\"sstart\") > pl.col(\"length\") - 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 18)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blast_cter.filter((pl.col(\"same_cluster\") == 1) & (pl.col(\"evalue\") < 0.5) & (pl.col(\"length\") < 60) & \n",
    "                     ((pl.col(\"q_specie\") == \"Scer_NCBI\") | (pl.col(\"s_specie\") == \"Spar_NCBI\"))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2995, 31)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nter.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
