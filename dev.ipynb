{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "from polars import NoDataError\n",
    "import numpy as np\n",
    "import gff3_parser\n",
    "import os \n",
    "import shutil\n",
    "import yaml\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import shutil\n",
    "import subprocess\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "\n",
    "from utils.files import multifasta_to_dict\n",
    "from utils.handle_UTRs import translate_frames\n",
    "from utils.process import get_specie\n",
    "\n",
    "\n",
    "gff_dict = dict()\n",
    "genome_dict = dict()\n",
    "\n",
    "\n",
    "\n",
    "with open('/home/simon.herman/Bureau/Gits/Elongates/env.yaml', 'r') as f:\n",
    "    yaml_data = yaml.safe_load(f)\n",
    "    species_order = yaml_data['Species_order']['Scer']\n",
    "    re_dict = yaml_data['Regex']['Scer']\n",
    "\n",
    "\n",
    "for specie in species_order:\n",
    "\n",
    "    gff_dict[specie] = pl.from_pandas(gff3_parser.parse_gff3(f\"input/{specie}.gff\", parse_attributes = True, verbose = False))\n",
    "    genome_dict[specie] = multifasta_to_dict(f\"input/{specie}.fna\", genome = True)\n",
    "\n",
    "\n",
    "cov = 0.50001\n",
    "coeff = 2\n",
    "seuil = 4\n",
    "\n",
    "current_path = f\"/home/simon.herman/Bureau/Gits/Elongates/work/{cov}\"\n",
    "elongates = pl.read_csv(f\"output/{cov}/{cov}_elongates.csv\", infer_schema_length =10000)\n",
    "\n",
    "\n",
    "def custom_target_elongate(cluster, scer_length, seq_id, specie, elongate_length, side, genome_dict, gff_dict, coeff = 1): \n",
    "\n",
    "\n",
    "    coordinates = list()\n",
    "    result_dict = dict()\n",
    "\n",
    "    if side != \"Nter\" and side != \"Cter\":\n",
    "\n",
    "        raise ValueError(\"Side must be either Nter or Cter\")\n",
    "    \n",
    "    gff = gff_dict[specie].filter(\n",
    "\n",
    "        (pl.col(\"Type\") == \"CDS\") & ((pl.col(\"Name\") == seq_id) | (pl.col(\"Parent\") == seq_id))\n",
    "\n",
    "    )[[\"Start\",\"End\",\"Strand\",\"Seqid\"]] # Keep only necessary columns\n",
    "    \n",
    "    # Store datas necessary to compute the elongate sequence\n",
    "\n",
    "    strand = gff[0][\"Strand\"].to_list()[0] # + or -\n",
    "    strand_id = gff[0][\"Seqid\"].to_list()[0] # chromosome or scaffold id\n",
    "\n",
    "    for row in gff.iter_rows(named=True): # Named = True to iter with column names\n",
    "\n",
    "        coordinates.append(sorted((int(row['Start'])-1, int(row['End'])-1))) # -1 for python indexing\n",
    "        \n",
    "    coordinates = sorted(coordinates, key=lambda x: x[0]) # Sort coordinates by start position\n",
    "\n",
    "\n",
    "    custom_elongate_length = int(np.ceil((scer_length - elongate_length) * 3 * coeff)) # Get the length of the elongate sequence in nucleotides\n",
    "\n",
    "    if strand == \"+\":\n",
    "\n",
    "        if side == \"Nter\":\n",
    "\n",
    "            start_5 = coordinates[0][0]-custom_elongate_length if coordinates[0][0]-custom_elongate_length >= 0 else 0 # Get the start position of the 5' UTR\n",
    "            \n",
    "            elongate = genome_dict[specie][strand_id][\"seq\"][\n",
    "\n",
    "                start_5:coordinates[0][0]\n",
    "\n",
    "            ] \n",
    "\n",
    "        elif side == \"Cter\": # Useless check but it's for the sake of clarity\n",
    "        \n",
    "            end_3 = coordinates[-1][1]+1+custom_elongate_length if coordinates[-1][1]+1+custom_elongate_length <= genome_dict[specie][strand_id][\"len\"] else genome_dict[specie][strand_id][\"len\"] # Get the end position of the 3' UTR\n",
    "            # +1 for -1,1 because GFF points to the last nucleotide of the stop codon\n",
    "\n",
    "            elongate = genome_dict[specie][strand_id][\"seq\"][\n",
    "                coordinates[-1][1]+1:end_3\n",
    "                ] # Get the 3' sequence\n",
    "\n",
    "    \n",
    "    # Reverse complement if the strand is negative, don't forget to reverse the coordinates\n",
    "    if strand == \"-\":\n",
    "\n",
    "        if side == \"Nter\":\n",
    "\n",
    "            end_5 = coordinates[-1][1]+1+custom_elongate_length if coordinates[-1][1]+1+custom_elongate_length <= genome_dict[specie][strand_id][\"len\"] else genome_dict[specie][strand_id][\"len\"] # Get the start position of the 5' UTR\n",
    "\n",
    "            elongate = genome_dict[specie][strand_id][\"seq\"][\n",
    "                coordinates[-1][1]+1:end_5\n",
    "            ].reverse_complement() # Get the 5' sequence\n",
    "        \n",
    "\n",
    "        if side == \"Cter\":\n",
    "        \n",
    "            start_3 = coordinates[0][0]-custom_elongate_length if coordinates[0][0]-custom_elongate_length >= 0 else 0 # Get the end position of the 3' UTR\n",
    "\n",
    "            elongate = genome_dict[specie][strand_id][\"seq\"][\n",
    "                start_3:coordinates[0][0]\n",
    "            ].reverse_complement() # Get the 3' sequence\n",
    "\n",
    "\n",
    "    result_dict[\"nuc\"] = SeqRecord(seq = Seq(elongate), id = f\"{seq_id}\", description = \"\") \n",
    "\n",
    "    # def translate_frames(dna_sequence, specie, seq_id, length, utr, cluster)\n",
    "\n",
    "    result_dict[\"prot\"] = translate_frames(dna_sequence = elongate, specie = specie, seq_id = seq_id, length = custom_elongate_length, utr = side, cluster = cluster)\n",
    "\n",
    "    return result_dict\n",
    "    \n",
    "    \n",
    "def custom_scer_elongates(scer_id : str, specie : str, scer_length : int, scer_elongate : str or Seq, infos_dict, cluster, gff_dict, genome_dict, side):\n",
    "\n",
    "    coordinates = list()\n",
    "    result_dict = dict()\n",
    "\n",
    "\n",
    "    ########\n",
    "    # Get infos from gff file \n",
    "    ########\n",
    "\n",
    "    if side != \"Nter\" and side != \"Cter\":\n",
    "\n",
    "        raise ValueError(\"Side must be either Nter or Cter\")\n",
    "    \n",
    "    gff = gff_dict[specie].filter(\n",
    "\n",
    "        (pl.col(\"Type\") == \"CDS\") & ((pl.col(\"Name\") == scer_id) | (pl.col(\"Parent\") == scer_id))\n",
    "\n",
    "    )[[\"Start\",\"End\",\"Strand\",\"Seqid\"]] # Keep only necessary columns\n",
    "    \n",
    "    # Store datas necessary to compute the elongate sequence\n",
    "\n",
    "    strand = gff[0][\"Strand\"].to_list()[0] # + or -\n",
    "    strand_id = gff[0][\"Seqid\"].to_list()[0] # chromosome or scaffold id\n",
    "\n",
    "    for row in gff.iter_rows(named=True): \n",
    "\n",
    "        coordinates.append(sorted((int(row['Start'])-1, int(row['End'])-1))) # -1 for python indexing\n",
    "        \n",
    "    coordinates = sorted(coordinates, key=lambda x: x[0]) # Sort coordinates by start position\n",
    "\n",
    "    ########\n",
    "    # Check that input data are correct\n",
    "    ########\n",
    "\n",
    "    scer_elongate = scer_elongate.replace(\"-\",\"\")\n",
    "\n",
    "    if len(scer_elongate) != scer_length:\n",
    "\n",
    "        print(f\"Seq id : {scer_id}\")\n",
    "        print(f\"Cluster : {cluster}\")\n",
    "        raise ValueError(\"Mismatch between theorical and real length of the Scer peptidic elongate\")\n",
    "\n",
    "    for subject_id, subject_length in infos_dict.items():\n",
    "\n",
    "        result_dict[subject_id] = dict()\n",
    "        custom_length = (scer_length-subject_length)*3\n",
    "\n",
    "        if strand == \"+\":\n",
    "\n",
    "            if side == \"Nter\":\n",
    "                \n",
    "               nuc_elongate = genome_dict[specie][strand_id][\"seq\"][\n",
    "\n",
    "                    coordinates[0][0]:coordinates[0][0] + custom_length # Get the 5' sequence\n",
    "\n",
    "                ] \n",
    "\n",
    "            elif side == \"Cter\": # Useless check but it's for the sake of clarity\n",
    "            \n",
    "\n",
    "                nuc_elongate = genome_dict[specie][strand_id][\"seq\"][\n",
    "                    \n",
    "                    coordinates[-1][1]-(custom_length):coordinates[-1][1]] # Get the 3' sequence\n",
    "\n",
    "    \n",
    "        # Reverse complement if the strand is negative, don't forget to reverse the coordinates\n",
    "        if strand == \"-\":\n",
    "\n",
    "            if side == \"Nter\":\n",
    "\n",
    "\n",
    "                nuc_elongate = genome_dict[specie][strand_id][\"seq\"][\n",
    "                    coordinates[-1][1]-(custom_length):coordinates[-1][1]\n",
    "                ].reverse_complement() # Get the 5' sequence\n",
    "            \n",
    "\n",
    "            elif side == \"Cter\":\n",
    "            \n",
    "                nuc_elongate = genome_dict[specie][strand_id][\"seq\"][\n",
    "                    coordinates[0][0]:coordinates[0][0] + (custom_length)\n",
    "                ].reverse_complement() # Get the 3' sequence\n",
    "\n",
    "\n",
    "\n",
    "        result_dict[subject_id][\"nuc\"] = SeqRecord( seq = Seq(nuc_elongate), id = f\"{scer_id}\", description = \"\")\n",
    "        result_dict[subject_id][\"prot\"] = SeqRecord( seq = Seq(scer_elongate[:int(custom_length/3)]), id = f\"{scer_id}\", description = \"\")\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def parse_prot_id(row : tuple) -> tuple:\n",
    "\n",
    "\n",
    "    prot_subject_pattern = r'(.*?)-(cluster_n\\d+)-(.*)-(f\\d+)-(\\d+)'\n",
    "\n",
    "    query_id = row[0]\n",
    "    subject_id = row[1]\n",
    "    identity = row[2]\n",
    "    align_lenght = row[3]\n",
    "    mismatches = row[4]\n",
    "    gap_opens = row[5]\n",
    "    qstart = row[6]\n",
    "    qend = row[7]\n",
    "    sstart = row[8]\n",
    "    send = row[9]\n",
    "    evalue = row[10]\n",
    "    bitscore = row[11]\n",
    "    condition = row[12]\n",
    "    side = row[13]\n",
    "\n",
    "    match = re.search(prot_subject_pattern, subject_id)\n",
    "\n",
    "\n",
    "    if match:\n",
    "\n",
    "        subject_id = match.group(1)\n",
    "        cluster = match.group(2)\n",
    "        relative_frame = match.group(4)\n",
    "\n",
    "\n",
    "    q_specie = get_specie(re_dict, query_id)\n",
    "    s_specie = get_specie(re_dict, subject_id)\n",
    "\n",
    "    return (query_id, subject_id, identity, align_lenght, mismatches, gap_opens, qstart, qend, sstart, send, evalue, bitscore, condition, side, relative_frame, q_specie, s_specie)\n",
    "\n",
    "\n",
    "def parse_nuc_id(row : tuple) -> tuple:\n",
    "\n",
    "\n",
    "    query_id = row[0]\n",
    "    subject_id = row[1]\n",
    "    identity = row[2]\n",
    "    align_lenght = row[3]\n",
    "    mismatches = row[4]\n",
    "    gap_opens = row[5]\n",
    "    qstart = row[6]\n",
    "    qend = row[7]\n",
    "    sstart = row[8]\n",
    "    send = row[9]\n",
    "    evalue = row[10]\n",
    "    bitscore = row[11]\n",
    "    condition = row[12]\n",
    "    side = row[13]\n",
    "\n",
    "    q_specie = get_specie(re_dict, query_id)\n",
    "    s_specie = get_specie(re_dict, subject_id)\n",
    "\n",
    "    return (query_id, subject_id, identity, align_lenght, mismatches, gap_opens, qstart, qend, sstart, send, evalue, bitscore, condition, side, \"NA\", q_specie, s_specie)\n",
    "\n",
    "\n",
    "Nter_scer_conditions = ((pl.col(\"species\") == \"Scer_NCBI\") & (abs(pl.col(\"max_Nter\") - pl.col(\"Nter_nb_aa\")) < seuil) & (pl.col(\"max_Nter\") >= 10))\n",
    "Cter_scer_conditions = ((pl.col(\"species\") == \"Scer_NCBI\") & (abs(pl.col(\"max_Cter\") - pl.col(\"Cter_nb_aa\")) < seuil) & (pl.col(\"max_Cter\") >= 10))\n",
    "test = elongates.filter(Nter_scer_conditions | Cter_scer_conditions)[\"cluster_name\"].unique().to_list()\n",
    "\n",
    "nter_clusters = []\n",
    "cter_clusters = []\n",
    "i = 0\n",
    "\n",
    "for cluster,sequences in elongates.filter(pl.col(\"cluster_name\").is_in(test)).groupby(\"cluster_name\"):\n",
    "\n",
    "    species = sequences[\"species\"].to_list()\n",
    "\n",
    "    if len(species) < 3:\n",
    "            \n",
    "        continue\n",
    "\n",
    "\n",
    "    species_ordered = [ s for s in species_order if s in species]\n",
    "    \n",
    "    if species_ordered[-1] != \"Scer_NCBI\" and species.count(species_ordered[-1]) > 1:\n",
    "            \n",
    "        continue\n",
    "\n",
    "    if sequences.filter(pl.col(\"species\") == species_ordered[-1])[\"Nter_nb_aa\"].to_list()[0] < seuil and sequences[\"max_Nter\"].max() >= 10:\n",
    "    \n",
    "        nter_clusters.append(cluster)\n",
    "\n",
    "    if sequences.filter(pl.col(\"species\") == species_ordered[-1])[\"Cter_nb_aa\"].to_list()[0] < seuil and sequences[\"max_Cter\"].max() >= 10:\n",
    "    \n",
    "        cter_clusters.append(cluster)\n",
    "\n",
    "\n",
    "\n",
    "full_filtered_Nter = elongates.filter(pl.col(\"cluster_name\").is_in(nter_clusters))\n",
    "full_filtered_Cter = elongates.filter(pl.col(\"cluster_name\").is_in(cter_clusters))\n",
    "\n",
    "dataframes = {\n",
    "        \"Nter\": full_filtered_Nter,\n",
    "        \"Cter\": full_filtered_Cter,\n",
    "    }\n",
    "\n",
    "current_path = f\"/home/simon.herman/Bureau/Gits/Elongates/work/{cov}\"\n",
    "\n",
    "if os.path.exists(f\"{current_path}/local_align_files\"):\n",
    "\n",
    "    shutil.rmtree(f\"{current_path}/local_align_files\")\n",
    "\n",
    "os.mkdir(f\"{current_path}/local_align_files\")\n",
    "\n",
    "for side in [\"Nter\", \"Cter\"]:\n",
    "\n",
    "    df = dataframes[side]\n",
    "\n",
    "    os.mkdir(f\"{current_path}/local_align_files/{side}\")\n",
    "\n",
    "    for cluster, sequences in df.groupby(\"cluster_name\"):\n",
    "\n",
    "        scer_length = sequences.filter(pl.col(\"species\") == \"Scer_NCBI\")[f\"{side}_nb_aa\"].max() # Maybe several Scer sequences in the cluster, we take the longest elongate\n",
    "        \n",
    "        if scer_length < 10:\n",
    "            continue\n",
    "\n",
    "        scer_id = sequences.filter((pl.col(\"species\") == \"Scer_NCBI\") & (pl.col(f\"{side}_nb_aa\") == scer_length))[\"seq_id\"].to_list()[0]\n",
    "        os.mkdir(f\"{current_path}/local_align_files/{side}/{cluster}\")\n",
    "    \n",
    "        infos_for_scer_sequences = dict()\n",
    "        for sequence in sequences.iter_rows(named = True): \n",
    "\n",
    "            if scer_length - sequence[f\"{side}_nb_aa\"] >= 10:\n",
    "\n",
    "\n",
    "                os.mkdir(f\"{current_path}/local_align_files/{side}/{cluster}/{sequence['seq_id']}\")\n",
    "                os.mkdir(f\"{current_path}/local_align_files/{side}/{cluster}/{sequence['seq_id']}/nucleotide\")\n",
    "                os.mkdir(f\"{current_path}/local_align_files/{side}/{cluster}/{sequence['seq_id']}/protein\")\n",
    "\n",
    "\n",
    "                dict_ = custom_target_elongate(cluster, scer_length, sequence[\"seq_id\"], sequence[\"species\"], sequence[f\"{side}_nb_aa\"], side, genome_dict, gff_dict, coeff = coeff)\n",
    "\n",
    "            \n",
    "                \n",
    "                SeqIO.write(dict_[\"nuc\"], f\"{current_path}/local_align_files/{side}/{cluster}/{sequence['seq_id']}/nucleotide/{sequence['seq_id']}.fna\", \"fasta\")\n",
    "                \n",
    "                SeqIO.write([ seq for seq in dict_[\"prot\"].values()], f\"{current_path}/local_align_files/{side}/{cluster}/{sequence['seq_id']}/protein/{sequence['seq_id']}.faa\", \"fasta\")\n",
    "                \n",
    "                infos_for_scer_sequences[sequence[\"seq_id\"]] = sequence[f\"{side}_nb_aa\"] \n",
    "                \n",
    "        \n",
    "        scer_cds = sequences.filter(pl.col(\"seq_id\") == scer_id)\n",
    "        \n",
    "        scer_elongates = custom_scer_elongates(scer_id = scer_id, specie = \"Scer_NCBI\", scer_length = scer_length, \n",
    "                                                    scer_elongate = scer_cds[f\"{side}_elongate\"].to_list()[0], infos_dict = infos_for_scer_sequences, \n",
    "                                                    cluster = cluster, gff_dict = gff_dict, genome_dict = genome_dict, side = side)\n",
    "\n",
    "\n",
    "        for subject_sequence in scer_elongates.keys():\n",
    "\n",
    "            SeqIO.write(scer_elongates[subject_sequence][\"nuc\"], f\"{current_path}/local_align_files/{side}/{cluster}/{subject_sequence}/nucleotide/{scer_id}_custom.fna\", \"fasta\")\n",
    "            SeqIO.write(scer_elongates[subject_sequence][\"prot\"], f\"{current_path}/local_align_files/{side}/{cluster}/{subject_sequence}/protein/{scer_id}_custom.faa\", \"fasta\")\n",
    "\n",
    "\n",
    "if os.path.exists(f\"{current_path}/local_align_files\"):\n",
    "\n",
    "    shutil.rmtree(f\"{current_path}/local_align_files\")\n",
    "\n",
    "os.mkdir(f\"{current_path}/local_align_files\")\n",
    "\n",
    "for side in [\"Nter\", \"Cter\"]:\n",
    "\n",
    "    df = dataframes[side]\n",
    "\n",
    "    os.mkdir(f\"{current_path}/local_align_files/{side}\")\n",
    "\n",
    "    for cluster, sequences in df.groupby(\"cluster_name\"):\n",
    "\n",
    "        scer_length = sequences.filter(pl.col(\"species\") == \"Scer_NCBI\")[f\"{side}_nb_aa\"].max() # Maybe several Scer sequences in the cluster, we take the longest elongate\n",
    "        \n",
    "        if scer_length < 10:\n",
    "            continue\n",
    "\n",
    "        scer_id = sequences.filter((pl.col(\"species\") == \"Scer_NCBI\") & (pl.col(f\"{side}_nb_aa\") == scer_length))[\"seq_id\"].to_list()[0]\n",
    "        os.mkdir(f\"{current_path}/local_align_files/{side}/{cluster}\")\n",
    "    \n",
    "        infos_for_scer_sequences = dict()\n",
    "        for sequence in sequences.iter_rows(named = True): \n",
    "\n",
    "            if scer_length - sequence[f\"{side}_nb_aa\"] >= 10:\n",
    "\n",
    "\n",
    "                os.mkdir(f\"{current_path}/local_align_files/{side}/{cluster}/{sequence['seq_id']}\")\n",
    "                os.mkdir(f\"{current_path}/local_align_files/{side}/{cluster}/{sequence['seq_id']}/nucleotide\")\n",
    "                os.mkdir(f\"{current_path}/local_align_files/{side}/{cluster}/{sequence['seq_id']}/protein\")\n",
    "\n",
    "\n",
    "                dict_ = custom_target_elongate(cluster, scer_length, sequence[\"seq_id\"], sequence[\"species\"], sequence[f\"{side}_nb_aa\"], side, genome_dict, gff_dict)\n",
    "\n",
    "            \n",
    "                \n",
    "                SeqIO.write(dict_[\"nuc\"], f\"{current_path}/local_align_files/{side}/{cluster}/{sequence['seq_id']}/nucleotide/{sequence['seq_id']}.fna\", \"fasta\")\n",
    "                \n",
    "                SeqIO.write([ seq for seq in dict_[\"prot\"].values()], f\"{current_path}/local_align_files/{side}/{cluster}/{sequence['seq_id']}/protein/{sequence['seq_id']}.faa\", \"fasta\")\n",
    "                \n",
    "                infos_for_scer_sequences[sequence[\"seq_id\"]] = sequence[f\"{side}_nb_aa\"] \n",
    "                \n",
    "        \n",
    "        scer_cds = sequences.filter(pl.col(\"seq_id\") == scer_id)\n",
    "        \n",
    "        scer_elongates = custom_scer_elongates(scer_id = scer_id, specie = \"Scer_NCBI\", scer_length = scer_length, \n",
    "                                                    scer_elongate = scer_cds[f\"{side}_elongate\"].to_list()[0], infos_dict = infos_for_scer_sequences, \n",
    "                                                    cluster = cluster, gff_dict = gff_dict, genome_dict = genome_dict, side = side)\n",
    "\n",
    "\n",
    "        for subject_sequence in scer_elongates.keys():\n",
    "\n",
    "            SeqIO.write(scer_elongates[subject_sequence][\"nuc\"], f\"{current_path}/local_align_files/{side}/{cluster}/{subject_sequence}/nucleotide/{scer_id}_custom.fna\", \"fasta\")\n",
    "            SeqIO.write(scer_elongates[subject_sequence][\"prot\"], f\"{current_path}/local_align_files/{side}/{cluster}/{subject_sequence}/protein/{scer_id}_custom.faa\", \"fasta\")\n",
    "\n",
    "\n",
    "# Fields: query id, subject id, % identity, alignment length, mismatches, gap opens, q. start, q. end, s. start, s. end, evalue, bit score\n",
    "dtypes = [pl.Utf8, pl.Utf8, pl.Float64, pl.Int64, pl.Int64, pl.Int64, pl.Int64, pl.Int64, pl.Int64, pl.Int64, pl.Float64, pl.Float64]\n",
    "dfs = list()\n",
    "trunc_files = open(f\"output/{cov}/trunc_files.txt\", \"a\")\n",
    "current_path = f\"/home/simon.herman/Bureau/Gits/Elongates/work/{cov}/local_align_files\"\n",
    "\n",
    "for side in os.listdir(current_path):\n",
    "\n",
    "    for cluster in os.listdir(f\"{current_path}/{side}\"):\n",
    "\n",
    "        for subject_seq in os.listdir(f\"{current_path}/{side}/{cluster}\"):\n",
    "\n",
    "            for condition in [\"nucleotide\",\"protein\"]:\n",
    "\n",
    "                root = f\"{current_path}/{side}/{cluster}/{subject_seq}/{condition}/\"\n",
    "                output_csv = os.path.join(root,\"temp.tsv\")      \n",
    "\n",
    "                if os.path.exists(output_csv):\n",
    "                    os.remove(output_csv)\n",
    "\n",
    "                to_align = os.listdir(f\"{current_path}/{side}/{cluster}/{subject_seq}/{condition}\")\n",
    "\n",
    "                query_index = next((i for i, item in enumerate(to_align) if \"custom\" in item))\n",
    "                subject_index = not query_index # List length 2 in every scenario\n",
    "\n",
    "                query = os.path.join(root, to_align[query_index])\n",
    "                subject = os.path.join(root, to_align[subject_index])      \n",
    "                \n",
    "                if condition == \"nucleotide\":\n",
    "                    command = f\"lalign36 -3 -E 1000 -m 8 {query} {subject} > {output_csv}\"\n",
    "                elif condition == \"protein\":\n",
    "                    command = f\"lalign36 -p -3 -E 1000 -m 8 {query} {subject} > {output_csv}\"\n",
    "                \n",
    "                subprocess.run(command, shell=True)\n",
    "                try:\n",
    "                    df = pl.read_csv(output_csv, separator=\"\\t\", has_header=False, dtypes = dtypes)\n",
    "                except:\n",
    "                    trunc_files.write(f\"{query}\\n{subject_index}\\n----------------\\n\")\n",
    "                    NoDataError()\n",
    "\n",
    "                if condition == \"nucleotide\":\n",
    "                    df = df.sort(\"column_11\", descending = False).head(1).with_columns(\n",
    "                        column_13 = pl.lit(condition),\n",
    "                        column_14 = pl.lit(side))\n",
    "\n",
    "                if condition == \"protein\":\n",
    "                    tmp_ = []\n",
    "                    for frame, align_res in df.groupby(\"column_2\"):\n",
    "                        tmp_.append(align_res.sort(\"column_11\", descending = False).head(1).with_columns(\n",
    "                            column_13 = pl.lit(condition),\n",
    "                            column_14 = pl.lit(side)))\n",
    "                    df = pl.concat(tmp_)\n",
    "\n",
    "                dfs.append(df)\n",
    "                os.remove(output_csv)\n",
    "                            \n",
    "df = pl.concat(dfs)\n",
    "trunc_files.close()\n",
    "\n",
    "df = pl.concat(dfs)\n",
    "df = df.with_columns(\n",
    "    \n",
    "    pl.lit(\"NA\").alias('column_15'),\n",
    "    pl.lit(\"NA\").alias('column_16'),\n",
    "    pl.lit(\"NA\").alias('column_17')\n",
    ")\n",
    "\n",
    "prot = df.filter(pl.col(\"column_13\") == \"protein\").apply(parse_prot_id)\n",
    "nuc = df.filter(pl.col(\"column_13\") == \"nucleotide\").apply(parse_nuc_id)\n",
    "\n",
    "\n",
    "df = pl.concat([prot, nuc]).rename({\n",
    "    \"column_0\": \"query_id\",\n",
    "    \"column_1\": \"subject_id\",\n",
    "    \"column_2\": \"identity\",\n",
    "    \"column_3\": \"align_lenght\",\n",
    "    \"column_4\": \"mismatches\",\n",
    "    \"column_5\": \"gap_opens\",\n",
    "    \"column_6\": \"qstart\",\n",
    "    \"column_7\": \"qend\",\n",
    "    \"column_8\": \"sstart\",\n",
    "    \"column_9\": \"send\",\n",
    "    \"column_10\": \"evalue\",\n",
    "    \"column_11\": \"bitscore\",\n",
    "    \"column_12\": \"condition\",\n",
    "    \"column_13\": \"side\",\n",
    "    \"column_14\": \"relative_frame\",\n",
    "    \"column_15\": \"q_specie\",\n",
    "    \"column_16\": \"s_specie\"\n",
    "}).sort(\"query_id\",\"subject_id\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"cluster_n2768\" in elongates[\"seq_id\"] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
