{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "import numpy as np\n",
    "cov = 0.5001\n",
    "\n",
    "\n",
    "elongates = pl.read_csv(f\"output/{cov}/{cov}_elongates.csv\", infer_schema_length =10000)\n",
    "\n",
    "def gini_coefficient(x):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute Gini coefficient of array of values\n",
    "    Source : https://stackoverflow.com/questions/39512260/calculating-gini-coefficient-in-python-numpy by Ulf Aslak\n",
    "    \"\"\"\n",
    "\n",
    "    diffsum = 0\n",
    "    for i, xi in enumerate(x[:-1], 1):\n",
    "        \n",
    "        print(i,xi)\n",
    "        diffsum += np.sum(np.abs(xi - x[i:]))\n",
    "        print(diffsum)\n",
    "    return diffsum / (len(x)**2 * np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "seuil = 4\n",
    "\n",
    "elongates = pl.read_csv(f\"output/{cov}/{cov}_elongates.csv\", infer_schema_length =10000)\n",
    "\n",
    "########\n",
    "# Get the clusters that are elongated in Scer but not in Sbay\n",
    "# Knowing well that such clusters include clusters without Sbay, or only with Scer or any other scenario \n",
    "########\n",
    "\n",
    "Nter_scer_conditions = ((pl.col(\"species\") == \"Scer_NCBI\") & (abs(pl.col(\"max_Nter\") - pl.col(\"Nter_nb_aa\")) < seuil) & (pl.col(\"max_Nter\") >= 10))\n",
    "Nter_sbay_conditions = ((pl.col(\"species\") == \"Sbay\") & (pl.col(\"Nter_nb_aa\") > seuil))\n",
    "\n",
    "Nter_scer_clusters = set(elongates.filter(Nter_scer_conditions)[\"cluster_name\"].to_list())\n",
    "Nter_sbay_clusters = set(elongates.filter(Nter_sbay_conditions)[\"cluster_name\"].to_list())\n",
    "\n",
    "Nter_clusters = elongates.filter(pl.col(\"cluster_name\").is_in(Nter_scer_clusters- Nter_sbay_clusters))\n",
    "\n",
    "\n",
    "\n",
    "Cter_scer_conditions = ((pl.col(\"species\") == \"Scer_NCBI\") & (abs(pl.col(\"max_Cter\") - pl.col(\"Cter_nb_aa\")) < seuil) & (pl.col(\"max_Cter\") >= 10))\n",
    "Cter_sbay_conditions = ((pl.col(\"species\") == \"Sbay\") & (pl.col(\"Cter_nb_aa\") > seuil))\n",
    "\n",
    "Cter_scer_clusters = set(elongates.filter(Cter_scer_conditions)[\"cluster_name\"].to_list())\n",
    "Cter_sbay_clusters = set(elongates.filter(Cter_sbay_conditions)[\"cluster_name\"].to_list())\n",
    "\n",
    "Cter_clusters = elongates.filter(pl.col(\"cluster_name\").is_in(Cter_scer_clusters- Cter_sbay_clusters))\n",
    "\n",
    "\n",
    "########\n",
    "# From those clusters, we want to keep only the ones that have Scer AND Sbay\n",
    "########\n",
    "\n",
    "\n",
    "# Nter\n",
    "scer_df_nter = set(Nter_clusters.filter(pl.col(\"species\") == \"Scer_NCBI\")[\"cluster_name\"].to_list())\n",
    "sbay_df_nter = set(Nter_clusters.filter(pl.col(\"species\") == \"Sbay\")[\"cluster_name\"].to_list())\n",
    "common = scer_df_nter.intersection(sbay_df_nter)\n",
    "\n",
    "full_filtered_Nter = Nter_clusters.filter(pl.col(\"cluster_name\").is_in(common)).sort(\"cluster_name\")\n",
    "\n",
    "# Cter\n",
    "scer_df_cter = set(Cter_clusters.filter(pl.col(\"species\") == \"Scer_NCBI\")[\"cluster_name\"].to_list())\n",
    "sbay_df_cter = set(Cter_clusters.filter(pl.col(\"species\") == \"Sbay\")[\"cluster_name\"].to_list())\n",
    "common = scer_df_cter.intersection(sbay_df_cter)\n",
    "\n",
    "full_filtered_Cter = Cter_clusters.filter(pl.col(\"cluster_name\").is_in(common)).sort(\"cluster_name\")\n",
    "\n",
    "\n",
    "# Question : are there some clusters that correspond to both Nter and Cter elongation criteria ?\n",
    "\n",
    "# Answer : \n",
    "\n",
    "# full_filtered_Nter.filter(pl.col(\"cluster_name\").is_in(full_filtered_Cter[\"cluster_name\"].unique().to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from utils.handle_UTRs import translate_frames\n",
    "\n",
    "\n",
    "def custom_target_elongate(cluster, scer_length, seq_id, specie, elongate_length, side, genome_dict, gff_dict): \n",
    "\n",
    "\n",
    "    coordinates = []\n",
    "\n",
    "    if side != \"Nter\" and side != \"Cter\":\n",
    "\n",
    "        raise ValueError(\"Side must be either Nter or Cter\")\n",
    "    \n",
    "    gff = gff_dict[specie].filter(\n",
    "\n",
    "        (pl.col(\"Type\") == \"CDS\") & ((pl.col(\"Name\") == seq_id) | (pl.col(\"Parent\") == seq_id))\n",
    "\n",
    "    )[[\"Start\",\"End\",\"Strand\",\"Seqid\"]] # Keep only necessary columns\n",
    "    \n",
    "    # Store datas necessary to compute the elongate sequence\n",
    "\n",
    "    strand = gff[0][\"Strand\"].to_list()[0] # + or -\n",
    "    strand_id = gff[0][\"Seqid\"].to_list()[0] # chromosome or scaffold id\n",
    "\n",
    "    for row in gff.iter_rows(named=True): # Named = True to iter with column names\n",
    "\n",
    "        coordinates.append(sorted((int(row['Start'])-1, int(row['End'])-1))) # -1 for python indexing\n",
    "        \n",
    "    coordinates = sorted(coordinates, key=lambda x: x[0]) # Sort coordinates by start position\n",
    "\n",
    "\n",
    "    custom_elongate_length = scer_length - elongate_length \n",
    "\n",
    "    if strand == \"+\":\n",
    "\n",
    "        if side == \"Nter\":\n",
    "\n",
    "            start_5 = coordinates[0][0]-custom_elongate_length if coordinates[0][0]-custom_elongate_length >= 0 else 0 # Get the start position of the 5' UTR\n",
    "            \n",
    "            elongate = genome_dict[specie][strand_id][\"seq\"][\n",
    "\n",
    "                start_5:coordinates[0][0]\n",
    "\n",
    "            ] \n",
    "\n",
    "        elif side == \"Cter\": # Useless check but it's for the sake of clarity\n",
    "        \n",
    "            end_3 = coordinates[-1][1]+1+custom_elongate_length if coordinates[-1][1]+1+custom_elongate_length <= genome_dict[specie][strand_id][\"len\"] else genome_dict[specie][strand_id][\"len\"] # Get the end position of the 3' UTR\n",
    "            # +1 for -1,1 because GFF points to the last nucleotide of the stop codon\n",
    "\n",
    "            elongate = genome_dict[specie][strand_id][\"seq\"][\n",
    "                coordinates[-1][1]+1:end_3\n",
    "                ] # Get the 3' sequence\n",
    "\n",
    "    \n",
    "    # Reverse complement if the strand is negative, don't forget to reverse the coordinates\n",
    "    if strand == \"-\":\n",
    "\n",
    "        if side == \"Nter\":\n",
    "\n",
    "            end_5 = coordinates[-1][1]+1+custom_elongate_length if coordinates[-1][1]+1+custom_elongate_length <= genome_dict[specie][strand_id][\"len\"] else genome_dict[specie][strand_id][\"len\"] # Get the start position of the 5' UTR\n",
    "\n",
    "            elongate = genome_dict[specie][strand_id][\"seq\"][\n",
    "                coordinates[-1][1]+1:end_5\n",
    "            ].reverse_complement() # Get the 5' sequence\n",
    "        \n",
    "\n",
    "        if side == \"Cter\":\n",
    "        \n",
    "            start_3 = coordinates[0][0]-custom_elongate_length if coordinates[0][0]-custom_elongate_length >= 0 else 0 # Get the end position of the 3' UTR\n",
    "\n",
    "            elongate = genome_dict[specie][strand_id][\"seq\"][\n",
    "                start_3:coordinates[0][0]\n",
    "            ].reverse_complement() # Get the 3' sequence\n",
    "\n",
    "\n",
    "    nucleotic_seq = SeqRecord(seq = Seq(elongate), id = f\"{seq_id}-{cluster}\", description = \"\")\n",
    "\n",
    "    # def translate_frames(dna_sequence, specie, seq_id, length, utr, cluster)\n",
    "\n",
    "    frames_dict = translate_frames(dna_sequence = nucleotic_seq, specie = specie, seq_id = seq_id, length = custom_elongate_length)\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import polars as pl\n",
    "import gff3_parser\n",
    "\n",
    "\n",
    "from utils import multifasta_to_dict\n",
    "\n",
    "cov = 0.5\n",
    "current_path = f\"/home/simon.herman/Bureau/Gits/Elongates/work/{cov}\"\n",
    "\n",
    "## Load data\n",
    "species = yaml.safe_load(open('env.yaml'))[\"Species_order\"][\"Scer\"] # Species will be passed as argument in the future\n",
    "elongates = pl.read_csv(f\"output/{cov}/{cov}_elongates.csv\", has_header = True, infer_schema_length = 5000)\n",
    "\n",
    "gff_dict = dict()\n",
    "genome_dict = dict()\n",
    "\n",
    "for specie in species:\n",
    "\n",
    "    gff_dict[specie] = pl.from_pandas(gff3_parser.parse_gff3(f\"input/{specie}.gff\", parse_attributes = True, verbose = False))\n",
    "    genome_dict[specie] = multifasta_to_dict(f\"input/{specie}.fna\", genome = True)\n",
    "\n",
    "#os.mkdir(f\"{current_path}/local_align_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "translate_frames() missing 1 required positional argument: 'cluster'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-1e6fe46cedae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscer_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{side}_nb_aa\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mdict_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_target_elongate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscer_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seq_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"species\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{side}_nb_aa\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenome_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgff_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seq_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Nter_nb_aa\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-201-e8867ab57c29>\u001b[0m in \u001b[0;36mcustom_target_elongate\u001b[0;34m(cluster, scer_length, seq_id, specie, elongate_length, side, genome_dict, gff_dict)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mframes_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnucleotic_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: translate_frames() missing 1 required positional argument: 'cluster'"
     ]
    }
   ],
   "source": [
    "dataframes = {\n",
    "    \"Nter\": full_filtered_Nter,\n",
    "    \"Cter\": full_filtered_Cter,\n",
    "}\n",
    "\n",
    "for side in [\"Nter\", \"Cter\"]:\n",
    "\n",
    "    df = dataframes[side]\n",
    "\n",
    "    #os.mkdir(f\"{current_path}/local_align_files/{side}\")\n",
    "\n",
    "    for cluster, sequences in df.groupby(\"cluster_name\"):\n",
    "\n",
    "        #os.mkdir(f\"{current_path}/local_align_files/{side}/{cluster}\")\n",
    "\n",
    "        scer_length = sequences.filter(pl.col(\"species\") == \"Scer_NCBI\")[f\"{side}_nb_aa\"].max() # Maybe several Scer sequences in the cluster, we take the longest elongate\n",
    "\n",
    "        input_dict = dict()\n",
    "\n",
    "        for sequence in sequences.iter_rows(named = True): \n",
    "\n",
    "            if scer_length - sequence[f\"{side}_nb_aa\"] >= 10:\n",
    "\n",
    "                dict_ = custom_target_elongate(cluster, scer_length, sequence[\"seq_id\"], sequence[\"species\"], sequence[f\"{side}_nb_aa\"], side, genome_dict, gff_dict)\n",
    "\n",
    "                input_dict[sequence[\"seq_id\"]] = sequence[\"Nter_nb_aa\"] \n",
    "                #os.mkdir(f\"{current_path}/local_align_files/{side}/{cluster}/{sequence['seq_id']}\")\n",
    "                #os.mkdir(f\"{current_path}/local_align_files/{side}/{cluster}/{sequence['seq_id']}/nucleotide\")\n",
    "                #os.mkdir(f\"{current_path}/local_align_files/{side}/{cluster}/{sequence['seq_id']}/protein\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
