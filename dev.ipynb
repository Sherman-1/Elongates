{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "import re\n",
    "import yaml \n",
    "from utils.process import get_specie\n",
    "\n",
    "# Load yaml file\n",
    "with open('/home/simon.herman/Bureau/Gits/Elongates/env.yaml', 'r') as f:\n",
    "    yaml_data = yaml.safe_load(f)\n",
    "    species_dict = {k: v for d in yaml_data['Regex'].values() for k, v in d.items()}\n",
    "    species_order = yaml_data['Species_order']['Scer']\n",
    "    re_dict = yaml_data['Regex']['Scer']\n",
    "\n",
    "\n",
    "def is_monophyletic(binary_vector):\n",
    "    try:\n",
    "        two_index = binary_vector.index(2)\n",
    "\n",
    "        ones_after_two = binary_vector[two_index:]\n",
    "        start_index = ones_after_two.index(1) + two_index\n",
    "        end_index = len(ones_after_two) - 1 - ones_after_two[::-1].index(1) + two_index\n",
    "\n",
    "        if 1 in binary_vector[:two_index] or 0 in binary_vector[start_index:end_index+1]:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_blast_dataframe(row : tuple) -> tuple:\n",
    "\n",
    "    query_pattern = r'(.*?)-(cluster_n\\d+)'\n",
    "    subject_pattern = r'(.*?)-(cluster_n\\d+)-.*-(f\\d+)-.*'\n",
    "\n",
    "    query_id = row[0]\n",
    "    subject_id = row[1]\n",
    "    evalue = row[2]\n",
    "    qstart = row[3]\n",
    "    qend = row[4]\n",
    "    sstart = row[5]\n",
    "    send = row[6]\n",
    "    qseq = row[7]\n",
    "    sseq = row[8]\n",
    "    length = row[9]\n",
    "\n",
    "\n",
    "\n",
    "    query_matches = re.match(query_pattern, query_id)\n",
    "    query_seq_id = query_matches.group(1) if query_matches else None\n",
    "    query_cluster = query_matches.group(2) if query_matches else None\n",
    "\n",
    "    subject_matches = re.match(subject_pattern, subject_id)\n",
    "    subject_seq_id = subject_matches.group(1) if subject_matches else None\n",
    "    subject_cluster = subject_matches.group(2) if subject_matches else None\n",
    "    subject_relative_frame = subject_matches.group(3) if subject_matches else None\n",
    "\n",
    "    is_same_cluster = int(query_cluster == subject_cluster)\n",
    "    q_specie = get_specie(re_dict, query_seq_id)\n",
    "    s_specie = get_specie(re_dict, subject_seq_id)\n",
    "\n",
    "    tuple_ = tuple([query_seq_id, subject_seq_id, evalue, qstart, qend, sstart, send, \n",
    "                    qseq, sseq, length, query_cluster, subject_cluster, subject_relative_frame, \n",
    "                    is_same_cluster, q_specie, s_specie])\n",
    "    return tuple_\n",
    "\n",
    "\n",
    "columns =  [\"qseqid\", \"sseqid\", \"evalue\", \"qstart\", \"qend\", \"sstart\", \"send\", \"qseq\", \"sseq\", \"length\"]\n",
    "df_nter  = pl.read_csv(\"output/nter_five.tsv\", separator=\"\\t\", has_header = False)\n",
    "df_cter  = pl.read_csv(\"output/cter_three.tsv\", separator=\"\\t\", has_header = False)\n",
    "df_nter.columns = columns\n",
    "df_cter.columns = columns\n",
    "\n",
    "df_nter = df_nter.with_columns(\n",
    "    pl.lit(\"NA\").alias('query_cluster'),\n",
    "    pl.lit(\"NA\").alias('subject_cluster'),\n",
    "    pl.lit(\"NA\").alias('relative_frame'),\n",
    "    pl.lit(\"NA\").alias('same_cluster'),\n",
    "    pl.lit(\"NA\").alias('q_specie'),\n",
    "    pl.lit(\"NA\").alias('s_specie')\n",
    ")\n",
    "\n",
    "df_cter = df_cter.with_columns(\n",
    "    pl.lit(\"NA\").alias('query_cluster'),\n",
    "    pl.lit(\"NA\").alias('subject_cluster'),\n",
    "    pl.lit(\"NA\").alias('relative_frame'),\n",
    "    pl.lit(\"NA\").alias('same_cluster'),\n",
    "    pl.lit(\"NA\").alias('q_specie'),\n",
    "    pl.lit(\"NA\").alias('s_specie')\n",
    ")\n",
    "\n",
    "columns = df_nter.columns\n",
    "df_nter = df_nter.apply(parse_blast_dataframe)\n",
    "df_nter.columns = columns\n",
    "\n",
    "columns = df_cter.columns\n",
    "df_cter = df_cter.apply(parse_blast_dataframe)\n",
    "df_cter.columns = columns              \n",
    "\n",
    "nter_data = pl.read_csv(\"output/0.5_elongates.csv\").select(\"cluster_size\",\"seq_id\",\n",
    "                                                           \"Nter_gaps\",\"Nter_gap_openings\",\"Nter_nb_aa\",\n",
    "                                                           \"Nter_elongate_length\",\"Nter_ratio\",\n",
    "                                                           \"is_max_Nter\",\"is_min_Nter\",\n",
    "                                                           \"Nter_event_ID\",\"Nter_events\",\n",
    "                                                           \"Meth_after_Nter\")\n",
    "\n",
    "cter_data = pl.read_csv(\"output/0.5_elongates.csv\").select(\"cluster_size\",\"seq_id\",\n",
    "                                                            \"Cter_gaps\",\"Cter_gap_openings\",\"Cter_nb_aa\",\n",
    "                                                            \"Cter_elongate_length\",\"Cter_ratio\",\n",
    "                                                            \"is_max_Cter\",\"is_min_Cter\",\n",
    "                                                            \"Cter_event_ID\",\"Cter_events\")\n",
    "\n",
    "df_nter = df_nter.join(nter_data, left_on=\"qseqid\", right_on=\"seq_id\")\n",
    "df_cter = df_cter.join(cter_data, left_on=\"qseqid\", right_on=\"seq_id\")\n",
    "\n",
    "tmp_id = list()\n",
    "tmp_vector = list()\n",
    "tmp_bool = list()\n",
    "for query, matches in df_nter.groupby(\"qseqid\"):\n",
    "\n",
    "    q_specie = matches[\"q_specie\"].unique().to_list()[0]\n",
    "    species = matches[\"s_specie\"].unique().to_list()\n",
    "    species = [1 if item in species else 0 for item in species_order]\n",
    "    tmp_id.append(query)\n",
    "    tmp_vector.append(str(species))\n",
    "    tmp_bool.append(False if 0 in species[species.index(1) : len(species) - species[::-1].index(1)] else True)\n",
    "\n",
    "\n",
    "nter_test = df_nter.join(pl.DataFrame({\n",
    "    'query': tmp_id,\n",
    "    'vector': tmp_vector,\n",
    "    'is_monophyletic': tmp_bool\n",
    "}), left_on=\"qseqid\", right_on=\"query\")\n",
    "\n",
    "\n",
    "tmp_id = list()\n",
    "tmp_vector = list()\n",
    "tmp_bool = list()\n",
    "for query, matches in df_cter.groupby(\"qseqid\"):\n",
    "\n",
    "    q_specie = matches[\"q_specie\"].unique().to_list()[0]\n",
    "    species = matches[\"s_specie\"].unique().to_list()\n",
    "    species = [1 if item in species else 0 for item in species_order]\n",
    "    tmp_id.append(query)\n",
    "    tmp_vector.append(str(species))\n",
    "    tmp_bool.append(False if 0 in species[species.index(1) : len(species) - species[::-1].index(1)] else True)\n",
    "\n",
    "cter_test = df_cter.join(pl.DataFrame({\n",
    "    'query': tmp_id,\n",
    "    'vector': tmp_vector,\n",
    "    'is_monophyletic': tmp_bool\n",
    "}), left_on=\"qseqid\", right_on=\"query\")\n",
    "\n",
    "nter_tmp = nter_test.filter(\n",
    "\n",
    "    (pl.col(\"same_cluster\") == 1) &\n",
    "    (pl.col(\"Nter_gap_openings\") <= 1) & \n",
    "    (pl.col(\"Nter_gaps\") <= 3) &\n",
    "    (pl.col(\"evalue\") < 1e-2) & \n",
    "    (pl.col(\"q_specie\") == \"Scer_NCBI\") & \n",
    "    (pl.col(\"is_monophyletic\") == True)\n",
    "\n",
    ").sort(\"qseqid\")\n",
    "\n",
    "cter_tmp = cter_test.filter(\n",
    "\n",
    "    (pl.col(\"same_cluster\") == 1) &\n",
    "    (pl.col(\"Cter_gap_openings\") <= 1) & \n",
    "    (pl.col(\"Cter_gaps\") <= 3) &\n",
    "    (pl.col(\"evalue\") < 1e-2) & \n",
    "    (pl.col(\"q_specie\") == \"Scer_NCBI\") & \n",
    "    (pl.col(\"is_monophyletic\") == True)\n",
    "\n",
    ").sort(\"qseqid\")\n",
    "\n",
    "print(df_nter.shape, df_cter.shape)\n",
    "# ((74, 28), (427, 29)) with mikate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8947, 27) (3884, 26)\n"
     ]
    }
   ],
   "source": [
    "print(df_nter.shape, df_cter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74, 28), (427, 29))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
